<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="An AI agent with one question box that helps older adults and people with cognitive differences complete tasks with a sentence.">
  <title>One-Question Assistant — Concept</title>
  <link rel="stylesheet" href="styles/style.css" />
</head>
<body>
  
<a href="#main" class="visually-hidden">Skip to content</a>
<header class="site-header">
  <div class="container" style="display:flex; align-items:center; gap:1rem;">
    <div class="brand">
      <div class="logo" aria-hidden="true"></div>
      <h1>One-Question Assistant</h1>
    </div>
    <nav class="primary" aria-label="Primary">
      <a href="index.html" aria-current="page">Concept</a>
      <a href="use_cases.html" >Use&nbsp;Cases</a>
    </nav>
  </div>
</header>

  <main id="main" class="container">

    <section class="panel split" aria-labelledby="p">
      <div>
        <h2 id="p">Problem</h2>
        <span class="micro s1">Bigger text isn’t the full answer</span>
<p>Many apps now ship a “Care Mode” for older adults, but most implementations stop at enlarging font size. Although bigger text can lead to recognitio, it does not explain <em>where</em> to go or <em>what</em> to press. For elderly or people with cognitive differences, the more difficult part is remembering complex unfamiliar names, recalling which app or website contains a certein function, and complex operation paths.</p>

<span class="micro s2">One question box, powered by AI</span>
<p>In order to solve this problem, I propose an AI assistant that matches how people naturally think: speak out what you want, and let the system guide the rest. The interface supports voice, typing, or handwriting. Instead of finding the Settings app, searching the web for a path, and clicking through nested menus, the assistant navigates on the user’s behalf and applies the change after a single confirmation.</p>
<p>Examples: “I want to change my wallpaper” shows a few labeled options and sets the chosen one; “How much storage or memory is used?” returns a plain summary with next-step tips; common services such as “Find nearby restaurants” or “Register at the hospital for next week” are aggregated behind the scenes so booking and queuing happen in one place.</p>

<span class="micro s2">Lower learning cost by mirroring everyday conversation</span>
<p>People already use conversation to solve problems in daily life, thus, such a system can effectively lowers the learning cost for seniors and users with cognitive differences: People no longer have to memorizing long operation paths or specific app/website functions. What they need is just express what they want to do.</p>

<span class="micro s2">Reducing inequality in access</span>
<p>Such an AI assistant that is easier to understand and operate can narrow the gap brought about by current technology. Previously, due to a lack of familiarity with the internet, I often saw elderly people in real life spending more money on goods or services on-site because they didn't know how to purchase coupons on mobile apps, and waiting for a long time in person because they couldn't use the online appointment service. Just because they are not so good at practical new technologies, they lost some resources that should have been within reach. Through my design, elderly people or special groups can discover coupons, make reservations or queue for meals, complete hospital registration online, etc. as easily as young people. This breaks the resource inequality caused by technology. In addition, in my Community Field Research, it was also shown that some elderly people feel "a little ashamed of always bothering their children" to help them with some operations, such as changing wallpaper. Through my design, special groups can feel more dignified.</p>

      </div>
      <div class="problem-right">
        <!-- 右上图 -->
        <figure class="figure fig-top">
          <img src="assets/images/problem-collage.png" alt="Collage: nested settings screens, tiny tap targets, multiple app flows.">
          <figcaption class="visually-hidden">problem-collage</figcaption>
        </figure>
        <!-- 右下图 -->
        <figure class="figure fig-bottom">
          <img src="assets/images/problem-access.png" alt="Elder using the assistant to find coupons, book restaurants, and register at hospitals in one place.">
          <figcaption class="visually-hidden">problem-access</figcaption>
        </figure>
      </div>
    </section>

    <section class="panel split flip" aria-labelledby="s">
      <figure class="figure">
        <img src="assets/images/one-input-ui.png" alt="Single large input with voice, typing, handwriting options.">
        <figcaption>/assets/images/one-input-ui.png</figcaption>
      </figure>
      <div>
        <h2 id="s">Solution Overview</h2>
        <span class="micro s1">One sentence to start</span>
        <p>The concept proposes a single question box handled by an AI agent. The user begins with one sentence in natural language and can choose voice, typing, or handwriting.</p>
        <span class="micro s2">Guided summary, single confirm</span>
        <p>Instead of learning menu paths, the user states the goal. The system presents a clear summary and one confirmation. Behind the scenes, the agent navigates settings or coordinates with apps on the user’s behalf.</p>
      </div>
    </section>

    <section class="panel split" aria-labelledby="t">
      <div>
        <h2 id="t">Target Users & Rationale</h2>
        <span class="micro s1">Natural conversation, lower load</span>
        <p>This design centers older adults and people with cognitive differences. It mirrors everyday conversation: say what you want, receive a straightforward response, move forward. By removing the need to memorize brand names and nested paths, the learning cost drops.</p>
        <div class="aside-note">
          <span class="micro s3">Outcome</span>
          <p class="muted">Greater independence in common tasks without relying on a family “interpreter.”</p>
        </div>
      </div>
      <figure class="figure">
        <img src="assets/images/confirm-card.png" alt="Confirmation card showing plain language summary and one action.">
        <figcaption>/assets/images/confirm-card.png</figcaption>
      </figure>
    </section>

<section class="panel" aria-labelledby="bridge">
  <h2 id="bridge">From Everyday Scenarios to a Future-Proof Assistant</h2>
  <span class="micro s2">A reusable pattern that scales</span>
  <p>This design is not tied to a single app. It follows a repeatable pattern—state intent → see a clear summary → confirm once—that can be applied to more services over time. As new integrations appear, the same interaction stays stable, so people do not have to relearn every brand’s rules.</p>

  <span class="micro s2">Future-facing by design</span>
  <p>Even our generation, fluent with today’s phones and websites, will one day meet unfamiliar tools. When that time comes, we will also need a way to adapt quickly. The same assistant can help us then: say what we want in everyday language, receive plain guidance, and learn how to use new technologies without starting from zero.</p>

  <div class="aside-note">
    <span class="micro s3">Long-term view</span>
    <p class="muted">Start with what matters most today, keep the interaction simple, and carry the same pattern forward as technology changes.</p>
  </div>
</section>

<section class="panel" aria-labelledby="pattern">
  <h2 id="pattern">Interaction Pattern</h2>

  <div class="pattern-cards">
    <article class="card">
      <span class="micro s1">Start with one sentence</span>
      <p>The assistant begins from natural language—voice, typing, or handwriting. People just speak or type out what they want to do using natual language.</p>
      <figure class="figure">
        <img src="assets/images/pattern-start.png" alt="Natural-language input: one large field with voice/typing/handwriting options (start step).">
        <figcaption class="visually-hidden">one-input-ui</figcaption>
      </figure>
      <p> Users can personalize the assistant’s avatar. Grandparents might choose a photo of their granddaughter, a beloved dog, or any image they love—the choice is entirely theirs. This simple touch makes the experience feel warmer and more familiar, reducing older adults’ resistance to learning complex smartphone systems and features, while also expressing the human-centered care at the heart of my future-facing design.</p>
      
    </article>

    <article class="card">
      <span class="micro s1">See clear options</span>
      <p>The system returns a small set of obvious choices, labeled in plain words. The goal stays in view; there is no need to switch apps or chase nested screens.</p>
      <figure class="figure">
        <img src="assets/images/pattern-options.png" alt="A small set of obvious options labeled in plain words (options step).">
        <figcaption class="visually-hidden">options-grid</figcaption>
      </figure>
    </article>

    <article class="card">
      <span class="micro s1">Confirm once, done</span>
      <p>A short summary appears. One confirmation applies the change or completes the task. The pattern is repeatable across settings, services, and future tools.</p>
      <figure class="figure">
        <img src="assets/images/pattern-confirm.png" alt="Plain summary and a single confirm action (confirmation step).">
        <figcaption class="visually-hidden">confirm-card</figcaption>
      </figure>
    </article>
  </div>
</section>

<section class="panel cta" aria-labelledby="cta">
  <h2 id="cta" class="visually-hidden">Learn More</h2>
  <p><a class="btn primary" href="use_cases.html">Explore Use Cases →</a></p>
</section>

  </main>
  
<footer role="contentinfo">
  <div class="container">
    <p>Concept: an AI agent for elders and people with cognitive differences. No functionality implemented.</p>
  </div>
</footer>

<script src="https://cdn.jsdelivr.net/npm/p5@1.9.0/lib/p5.min.js"></script>
<script defer src="scripts/rain.js"></script>

</body>
</html>
